{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2 as cv\n",
    "import numpy as np \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                                                                rescale = 1/255.0,  # Rescale... 0 to 1 .. 0 is white colors and 1 is black colors\n",
    "                                                                rotation_range=20,\n",
    "                                                                width_shift_range=0.2,\n",
    "                                                                height_shift_range=0.20,\n",
    "                                                                horizontal_flip=True,\n",
    "                                                                vertical_flip=True\n",
    "                                                                )\n",
    "\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                                                                rescale = 1/255.0,\n",
    "                                                                rotation_range=20,\n",
    "                                                                width_shift_range=0.2,\n",
    "                                                                height_shift_range=0.20,\n",
    "                                                                horizontal_flip=True,\n",
    "                                                                vertical_flip=True\n",
    "                                                                )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                                    directory='data/train',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    batch_size=12,\n",
    "                                                    class_mode='binary',\n",
    "                                                    shuffle=True,\n",
    "                                                    seed=42\n",
    "                                                    )\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "                                                    directory='data/validation',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    batch_size=12,\n",
    "                                                    class_mode='binary',\n",
    "                                                    shuffle=True,\n",
    "                                                    seed=42\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 111, 111, 64)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 26, 26, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 12, 12, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 10, 10, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 5, 5, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3200)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1638912   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2288897 (8.73 MB)\n",
      "Trainable params: 2288897 (8.73 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# sequential API \n",
    "\n",
    "# To improve accuract  i added another two Convolutional layers and also a Max Pool Layer\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Conv2D(64, (3,3), input_shape=(224,224,3), activation = 'relu'),\n",
    "                            tf.keras.layers.MaxPool2D(2,2),\n",
    "                            tf.keras.layers.Conv2D(128, (3,3), activation = 'relu'),\n",
    "                            tf.keras.layers.MaxPool2D(2,2),\n",
    "                            tf.keras.layers.Conv2D(128, (3,3), activation = 'relu'),\n",
    "                            tf.keras.layers.MaxPool2D(2,2),\n",
    "                            tf.keras.layers.Conv2D(128, (3,3), activation = 'relu'),\n",
    "                            tf.keras.layers.MaxPool2D(2,2),\n",
    "                            tf.keras.layers.Conv2D(128, (3,3), activation = 'relu'),\n",
    "                            tf.keras.layers.MaxPool2D(2,2),\n",
    "                            tf.keras.layers.Flatten(),\n",
    "                            tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "                            tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "                            tf.keras.layers.Dense(1, activation='sigmoid')    \n",
    "                        ])\n",
    "model.summary()\n",
    "# functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "86/86 [==============================] - 39s 451ms/step - loss: 0.6959 - accuracy: 0.5015 - val_loss: 0.6963 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "86/86 [==============================] - 45s 518ms/step - loss: 0.6300 - accuracy: 0.6563 - val_loss: 0.7832 - val_accuracy: 0.6133\n",
      "Epoch 3/20\n",
      "86/86 [==============================] - 37s 423ms/step - loss: 0.4753 - accuracy: 0.8062 - val_loss: 1.9323 - val_accuracy: 0.6641\n",
      "Epoch 4/20\n",
      "86/86 [==============================] - 36s 416ms/step - loss: 0.3471 - accuracy: 0.8715 - val_loss: 0.8687 - val_accuracy: 0.8047\n",
      "Epoch 5/20\n",
      "86/86 [==============================] - 38s 446ms/step - loss: 0.3096 - accuracy: 0.8724 - val_loss: 1.5907 - val_accuracy: 0.7266\n",
      "Epoch 6/20\n",
      "86/86 [==============================] - 35s 409ms/step - loss: 0.2561 - accuracy: 0.8997 - val_loss: 1.1429 - val_accuracy: 0.8047\n",
      "Epoch 7/20\n",
      "86/86 [==============================] - 35s 409ms/step - loss: 0.2084 - accuracy: 0.9231 - val_loss: 1.3099 - val_accuracy: 0.8047\n",
      "Epoch 8/20\n",
      "86/86 [==============================] - 35s 411ms/step - loss: 0.2234 - accuracy: 0.9221 - val_loss: 1.3376 - val_accuracy: 0.7734\n",
      "Epoch 9/20\n",
      "86/86 [==============================] - 35s 411ms/step - loss: 0.1764 - accuracy: 0.9250 - val_loss: 0.9806 - val_accuracy: 0.8633\n",
      "Epoch 10/20\n",
      "86/86 [==============================] - 35s 406ms/step - loss: 0.2042 - accuracy: 0.9211 - val_loss: 1.7581 - val_accuracy: 0.8320\n",
      "Epoch 11/20\n",
      "86/86 [==============================] - 37s 435ms/step - loss: 0.2154 - accuracy: 0.9172 - val_loss: 0.4535 - val_accuracy: 0.8711\n",
      "Epoch 12/20\n",
      "86/86 [==============================] - 36s 423ms/step - loss: 0.1867 - accuracy: 0.9416 - val_loss: 0.5963 - val_accuracy: 0.8242\n",
      "Epoch 13/20\n",
      "86/86 [==============================] - 37s 425ms/step - loss: 0.1257 - accuracy: 0.9484 - val_loss: 1.3039 - val_accuracy: 0.8359\n",
      "Epoch 14/20\n",
      "86/86 [==============================] - 37s 424ms/step - loss: 0.1053 - accuracy: 0.9601 - val_loss: 0.6183 - val_accuracy: 0.8359\n",
      "Epoch 15/20\n",
      "86/86 [==============================] - 39s 446ms/step - loss: 0.1336 - accuracy: 0.9533 - val_loss: 0.7801 - val_accuracy: 0.8320\n",
      "Epoch 16/20\n",
      "86/86 [==============================] - 37s 426ms/step - loss: 0.1036 - accuracy: 0.9591 - val_loss: 1.8698 - val_accuracy: 0.8203\n",
      "Epoch 17/20\n",
      "86/86 [==============================] - 41s 479ms/step - loss: 0.1082 - accuracy: 0.9669 - val_loss: 0.3628 - val_accuracy: 0.8984\n",
      "Epoch 18/20\n",
      "86/86 [==============================] - 39s 450ms/step - loss: 0.0951 - accuracy: 0.9679 - val_loss: 1.0834 - val_accuracy: 0.8477\n",
      "Epoch 19/20\n",
      "86/86 [==============================] - 37s 427ms/step - loss: 0.0941 - accuracy: 0.9581 - val_loss: 0.8293 - val_accuracy: 0.8633\n",
      "Epoch 20/20\n",
      "86/86 [==============================] - 38s 435ms/step - loss: 0.0839 - accuracy: 0.9688 - val_loss: 0.8389 - val_accuracy: 0.8945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2900bc7f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "            loss = 'binary_crossentropy',\n",
    "            optimizer = 'adam',\n",
    "            metrics=['accuracy']\n",
    "            )\n",
    "\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        validation_data=valid_generator,\n",
    "        epochs=20\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'horses': 0, 'humans': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'HORSE'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inference(image_path):\n",
    "    img = cv.imread(image_path)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    img = cv.resize(img, (224,224))\n",
    "    img = img / 255.0\n",
    "    img = np.array([img])\n",
    "    P = model.predict(img).squeeze()\n",
    "    return 'HUMAN' if P > 0.5 else 'HORSE'\n",
    "    \n",
    "inference('data/train/horses/horse01-9.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
